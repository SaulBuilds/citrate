{
    "Lattice Model Class": {
        "prefix": "lattice-model",
        "body": [
            "from typing import Dict, Any",
            "",
            "class LatticeModel:",
            "    \"\"\"",
            "    Lattice AI Model for blockchain deployment.",
            "    \"\"\"",
            "",
            "    def __init__(self):",
            "        self.model_id = None",
            "        self.version = \"1.0.0\"",
            "",
            "    def predict(self, input_data: Dict[str, Any]) -> Dict[str, Any]:",
            "        \"\"\"",
            "        Make predictions using the model.",
            "        ",
            "        Args:",
            "            input_data: Input data for prediction",
            "        ",
            "        Returns:",
            "            Dictionary containing prediction results",
            "        \"\"\"",
            "        # TODO: Implement your model logic here",
            "        return {",
            "            \"prediction\": $1,",
            "            \"confidence\": $2,",
            "            \"model_version\": self.version",
            "        }",
            "",
            "    def validate_input(self, input_data: Dict[str, Any]) -> bool:",
            "        \"\"\"Validate input data format\"\"\"",
            "        # TODO: Add validation logic",
            "        return True"
        ],
        "description": "Create a Lattice AI model class"
    },
    "Lattice Deploy Script": {
        "prefix": "lattice-deploy",
        "body": [
            "#!/usr/bin/env python3",
            "\"\"\"",
            "Lattice Model Deployment Script",
            "\"\"\"",
            "",
            "import asyncio",
            "from lattice_sdk import LatticeClient",
            "",
            "async def deploy_model():",
            "    \"\"\"Deploy model to Lattice blockchain\"\"\"",
            "    client = LatticeClient(\"http://localhost:8545\")",
            "    ",
            "    # Load model",
            "    with open(\"$1\", \"rb\") as f:",
            "        model_data = f.read()",
            "    ",
            "    # Model metadata",
            "    metadata = {",
            "        \"name\": \"$2\",",
            "        \"version\": \"$3\",",
            "        \"description\": \"$4\",",
            "        \"tags\": [\"$5\"]",
            "    }",
            "    ",
            "    # Deploy",
            "    result = await client.deploy_model(",
            "        model_data=model_data,",
            "        metadata=metadata,",
            "        price=\"1000000000000000000\",  # 1 ETH",
            "        encrypted=False",
            "    )",
            "    ",
            "    print(f\"Model deployed: {result.model_id}\")",
            "    print(f\"Transaction: {result.tx_hash}\")",
            "",
            "if __name__ == \"__main__\":",
            "    asyncio.run(deploy_model())"
        ],
        "description": "Create a Lattice model deployment script"
    },
    "Lattice Inference": {
        "prefix": "lattice-inference",
        "body": [
            "import asyncio",
            "from lattice_sdk import LatticeClient",
            "",
            "async def run_inference():",
            "    \"\"\"Run inference on deployed model\"\"\"",
            "    client = LatticeClient(\"http://localhost:8545\")",
            "    ",
            "    # Input data",
            "    input_data = {",
            "        \"$1\": \"$2\"",
            "    }",
            "    ",
            "    # Run inference",
            "    result = await client.run_inference(",
            "        model_id=\"$3\",",
            "        input_data=input_data",
            "    )",
            "    ",
            "    print(f\"Result: {result.output_data}\")",
            "    print(f\"Gas used: {result.gas_used}\")",
            "    print(f\"Execution time: {result.execution_time}ms\")",
            "",
            "if __name__ == \"__main__\":",
            "    asyncio.run(run_inference())"
        ],
        "description": "Create a Lattice inference script"
    },
    "Lattice Test": {
        "prefix": "lattice-test",
        "body": [
            "import unittest",
            "import asyncio",
            "from lattice_sdk import LatticeClient",
            "",
            "class TestLatticeModel(unittest.TestCase):",
            "    \"\"\"Test cases for Lattice model\"\"\"",
            "    ",
            "    def setUp(self):",
            "        self.client = LatticeClient(\"http://localhost:8545\")",
            "    ",
            "    async def test_model_deployment(self):",
            "        \"\"\"Test model deployment\"\"\"",
            "        # TODO: Implement deployment test",
            "        pass",
            "    ",
            "    async def test_inference(self):",
            "        \"\"\"Test model inference\"\"\"",
            "        # TODO: Implement inference test",
            "        pass",
            "    ",
            "    def test_$1(self):",
            "        \"\"\"Test $2\"\"\"",
            "        # TODO: Implement test",
            "        self.assertTrue(True)",
            "",
            "if __name__ == \"__main__\":",
            "    unittest.main()"
        ],
        "description": "Create Lattice model test cases"
    }
}