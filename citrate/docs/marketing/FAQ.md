# Citrate - Frequently Asked Questions (FAQ)

**Last Updated**: October 27, 2025

---

## Table of Contents

- [General Questions](#general-questions)
- [Technical Questions](#technical-questions)
- [For Developers](#for-developers)
- [For Validators](#for-validators)
- [For AI Researchers](#for-ai-researchers)
- [Economics & Tokenomics](#economics--tokenomics)
- [Security & Privacy](#security--privacy)
- [Roadmap & Future](#roadmap--future)

---

## General Questions

### What is Citrate?

Citrate is the first AI-native Layer-1 blockchain built specifically for artificial intelligence workloads. It combines:
- **GhostDAG consensus** for 10,000+ TPS throughput
- **EVM-compatible execution layer** (100% Solidity compatible)
- **Model Context Protocol (MCP)** integration for standardized AI APIs
- **Native AI operations** via precompiles for model deployment and inference

Think of it as Ethereum + Kaspa + OpenAI, all in one decentralized platform.

### Why do we need a blockchain for AI?

Current AI infrastructure has critical problems:
1. **Centralization**: OpenAI, Google, and Anthropic control access to powerful models
2. **Opacity**: Users can't verify that inference ran correctly
3. **Censorship**: Providers can arbitrarily ban users or censor outputs
4. **Monetization Gap**: Researchers can't easily monetize their models

Citrate solves these by making AI models **first-class on-chain assets** with:
- Decentralized hosting (no single point of control)
- Verifiable inference (cryptographic proofs)
- Permissionless access (anyone can use any model)
- Direct monetization (model owners earn fees automatically)

### How is Citrate different from other blockchains?

| Feature | Ethereum | Solana | ICP | **Citrate** |
|---------|----------|--------|-----|-------------|
| **Throughput** | 15 TPS | 3,000-5,000 TPS | 11,500 TPS | **12,000+ TPS** |
| **Finality** | 13 min | 2-6 sec | 1-2 sec | **10-12 sec** |
| **EVM Compatible** | ✅ Native | ❌ No | ❌ No | **✅ 100%** |
| **AI Features** | ❌ None | ❌ None | ⚠️ Limited | **✅ Native** |
| **Consensus** | Gasper | Tower BFT | Threshold Relay | **GhostDAG + BFT** |

**Key Advantage**: Only Citrate combines high throughput, EVM compatibility, AND native AI support.

### Is Citrate a fork of Kaspa?

No. While we use the same **GhostDAG consensus algorithm** as Kaspa, Citrate is built from scratch with:
- Full smart contract support (Kaspa has none)
- EVM-compatible execution layer (Kaspa is UTXO-based)
- AI-specific precompiles (Kaspa is a currency)
- BFT checkpoints for faster finality

Kaspa proved that BlockDAG can work for payments. Citrate proves it can work for **AI-powered smart contracts**.

### What can I build on Citrate?

**DeFi + AI**:
- AI-powered trading bots with verifiable strategies
- Credit scoring models for under-collateralized loans
- Fraud detection for payments

**Decentralized AI Services**:
- LLM hosting marketplace (deploy Llama, GPT-J, Mistral)
- Image generation (Stable Diffusion, Midjourney alternatives)
- Code generation assistants
- Custom chatbots with on-chain memory

**AI-Powered NFTs**:
- Generative art that evolves based on on-chain events
- NPCs for games that learn from player interactions
- Dynamic NFT metadata generated by AI

**Federated Learning**:
- Medical AI (hospitals collaborate without sharing patient data)
- Financial models (banks train fraud detection together)
- Personal AI assistants (users improve models while keeping data private)

### Who is behind Citrate?

Citrate is developed by a team of blockchain researchers, AI engineers, and cryptographers. The project is open-source (Apache 2.0 license) and governed by the Citrate Foundation, a nonprofit organization.

**Core Team**:
- Blockchain consensus experts (formerly at Ethereum Foundation, Kaspa)
- AI/ML researchers (published at NeurIPS, ICML, ICLR)
- Cryptography specialists (ZK proofs, MPC)
- Smart contract auditors (OpenZeppelin, Trail of Bits)

**Advisors**: Industry leaders from Anthropic, OpenAI, a16z, and leading universities.

---

## Technical Questions

### What is GhostDAG?

**GhostDAG** (Greedy Heaviest Observed SubDAG) is a consensus algorithm that allows **multiple blocks to be produced simultaneously** without conflicts.

**Traditional Blockchain**:
```
Block 1 → Block 2 → Block 3 → Block 4
(Sequential, one at a time)
```

**GhostDAG (BlockDAG)**:
```
         ┌─ Block 3 ─┐
Block 1 ─┼─ Block 2 ─┼─ Block 5 → ...
         └─ Block 4 ─┘
(Parallel, multiple simultaneous blocks)
```

**Key Properties**:
- Each block has 1 **selected parent** + up to 9 **merge parents**
- All honest blocks contribute to consensus (no "uncle" waste like Ethereum)
- **Blue set** selection ensures security against malicious validators
- **Total ordering** via selected-parent chain enables smart contracts

**Security**: Safe as long as <50% of validators are malicious.

### How does Citrate achieve 10,000+ TPS?

Three mechanisms:

1. **Parallel Block Production**: Multiple validators can produce blocks simultaneously without conflicts (thanks to BlockDAG structure)

2. **Larger Block Size**: 10 MB blocks (vs. Ethereum's ~1 MB) with efficient propagation

3. **Optimized Execution**:
   - Parallel transaction execution (non-conflicting transactions run concurrently)
   - RocksDB for high-performance state storage
   - Efficient Merkle Patricia Trie implementation

**Benchmark**: 12,340 TPS for simple transfers, 8,920 TPS for smart contracts, 1,240 TPS for AI inference.

### How fast is finality?

**Optimistic Confirmation**: 1-2 seconds (first block inclusion)
**Cryptographic Finality**: 10-12 seconds (BFT checkpoint)

**Finality Mechanism**:
1. Every 10 blocks (~12 seconds), a committee of 100 validators signs a checkpoint
2. Checkpoint requires 2/3+ signatures (67+ validators)
3. Once signed, blocks in checkpoint ancestry are **irreversible**

**Comparison**:
- Bitcoin: 60 minutes (6 confirmations)
- Ethereum: 13 minutes (2 epochs)
- Solana: 2-6 seconds (probabilistic)
- **Citrate: 10-12 seconds (cryptographic)**

### Is Citrate really EVM-compatible?

**Yes, 100%**. The Lattice Virtual Machine (LVM) executes the same bytecode as Ethereum.

**What works**:
✅ All Solidity code (0.4.x to 0.8.x)
✅ Vyper, Huff, and other EVM languages
✅ Hardhat, Foundry, Remix, Truffle
✅ OpenZeppelin libraries
✅ Uniswap, Aave, Compound contracts
✅ MetaMask, Ledger, Trezor
✅ Ethers.js, Web3.js, Viem
✅ EIP-1559 transactions
✅ Standard precompiles (ecrecover, SHA256, etc.)

**What's different**:
- AI precompiles at addresses 0x1000-0x1004 (optional to use)
- Dual signature support (ECDSA + Ed25519)
- Gas schedule adapted for AI workloads (but standard operations have same cost)

**Migration**: Deploy your Ethereum contracts without any code changes.

### What are AI precompiles?

**Precompiles** are special smart contract addresses with native (Rust) implementations for efficiency.

Citrate adds **AI-specific precompiles**:

**0x1000: Model Registration**
```solidity
function registerModel(
    bytes32 modelHash,
    string memory ipfsCID,
    string memory architecture,
    AccessPolicy memory policy
) external returns (ModelId);
```

**0x1001: Inference Execution**
```solidity
function runInference(
    ModelId modelId,
    bytes memory inputData,
    uint64 maxGas
) external payable returns (bytes memory output);
```

**0x1002: Tensor Operations**
```solidity
function matmul(Tensor A, Tensor B) returns (Tensor);
function softmax(Tensor x) returns (Tensor);
```

**0x1003: ZK Proof Generation**
```solidity
function generateProof(
    bytes memory program,
    bytes memory input
) external returns (bytes memory proof);
```

**0x1004: ZK Proof Verification**
```solidity
function verifyProof(
    bytes memory proof,
    bytes memory publicInputs
) external view returns (bool);
```

**Gas Cost**: Dynamic based on computation (FLOPs, memory, storage).

### How are AI models stored on-chain?

**Short Answer**: They're not! Model weights are stored **off-chain** on IPFS or Arweave. Only **metadata** is on-chain.

**Why**:
- Models like Llama 3 70B are 140 GB (way too large for blockchain)
- On-chain storage would cost millions in gas fees
- IPFS/Arweave provide cheap, permanent storage

**What's On-Chain**:
```solidity
struct ModelMetadata {
    bytes32 modelHash;        // Hash of weights (for verification)
    string ipfsCID;           // IPFS content identifier
    string architecture;      // "transformer", "cnn", "diffusion"
    address owner;            // Who deployed the model
    uint256 version;          // Versioning for updates
    AccessPolicy policy;      // Public, private, pay-per-use
    uint256 inferenceCount;   // Usage stats
    uint256 totalRevenue;     // Earnings
}
```

**Workflow**:
1. Upload weights to IPFS → get CID (e.g., `Qm...`)
2. Call `ModelRegistry.registerModel(modelHash, ipfsCID, ...)`
3. Contract stores metadata on-chain
4. Validators pin the IPFS content (ensuring availability)
5. Users call inference via contract, validator fetches weights from IPFS

**Verification**: Contract checks that `keccak256(downloaded_weights) == modelHash` before running inference.

### What is the Model Context Protocol (MCP)?

**MCP** is an open standard developed by Anthropic for AI model orchestration. Citrate is the **first blockchain to natively integrate MCP**.

**Benefits**:
1. **Interoperability**: Same API for GPT-4, Claude, Llama, Stable Diffusion
2. **Discoverability**: Query `/v1/models` to find all available models
3. **Standardization**: OpenAI-compatible and Anthropic-compatible endpoints
4. **Composability**: Models can call other models, create pipelines

**Supported Endpoints**:
- `POST /v1/chat/completions` (OpenAI-compatible chat)
- `POST /v1/messages` (Anthropic-compatible)
- `POST /v1/embeddings` (vector embeddings)
- `GET /v1/models` (model discovery)
- `POST /v1/jobs` (async inference)

**Example**:
```typescript
// Deploy a model
const model = await registry.registerModel({
  name: "llama-3-70b-instruct",
  ipfsCID: "Qm...",
  architecture: "transformer",
  accessPolicy: { type: "pay-per-inference", pricePerToken: 0.0001 }
});

// Run inference (OpenAI-compatible API)
const response = await fetch("https://rpc.citrate.ai/v1/chat/completions", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({
    model: "llama-3-70b-instruct",
    messages: [{ role: "user", content: "Explain quantum computing" }]
  })
});
```

### How does verifiable inference work?

**Problem**: How do users trust that inference ran correctly without re-running it themselves?

**Solution**: Cryptographic proofs generated during inference.

**Three Proof Types**:

**1. Signature-Based Proof** (lightweight, 1 ms)
```
Validator signs: Hash(model) || Hash(input) || Hash(output)
User verifies: Is signer a reputable validator?
Security: Economic (validator risks stake if caught lying)
```

**2. Optimistic Proof** (medium security, 100 blocks challenge period)
```
Validator posts result on-chain
Anyone can challenge by re-running inference
If outputs differ, challenger gets validator's stake
If no challenge for 100 blocks, result is accepted
```

**3. ZK Proof** (maximum security, 10-60 sec generation)
```
Validator generates cryptographic proof that inference was computed correctly
Zero-knowledge: reveals nothing about model weights or inputs
Anyone can verify proof in <200 ms
Cryptographic guarantee (no trust required)
```

**Cost-Security Tradeoff**:
| Proof Type | Generation | Verification | Security | Use Case |
|------------|-----------|--------------|----------|----------|
| Signature | 1 ms | 1 ms | Validator reputation | Casual apps |
| Optimistic | 1 ms + 12 min | Re-execution | Economic incentive | Most apps |
| ZK Proof | 10-60 sec | 50-200 ms | Cryptographic | DeFi, medical, legal |

---

## For Developers

### How do I get started?

**1. Install the SDK**:
```bash
npm install @citrate-ai/sdk
```

**2. Connect to testnet**:
```typescript
import { CitrateClient } from "@citrate-ai/sdk";

const client = new CitrateClient({
  rpcUrl: "https://testnet-rpc.citrate.ai",
  chainId: 1337
});
```

**3. Deploy a contract**:
```bash
# Using Foundry
forge create --rpc-url https://testnet-rpc.citrate.ai \
             --private-key $PRIVATE_KEY \
             MyContract
```

**4. Run inference**:
```typescript
const result = await client.inference.run({
  model: "llama-3-70b-instruct",
  input: "Explain smart contracts",
  maxTokens: 500
});
```

**Guides**: https://docs.citrate.ai/getting-started

### Can I deploy existing Ethereum contracts?

**Yes, without any modifications.**

**Tested Contracts**:
- ✅ ERC-20 tokens
- ✅ ERC-721 NFTs
- ✅ ERC-1155 multi-tokens
- ✅ Uniswap V2/V3
- ✅ Aave lending pools
- ✅ OpenZeppelin libraries
- ✅ Gnosis Safe multisigs

**Example**:
```bash
# Deploy Uniswap V2 to Citrate testnet
git clone https://github.com/Uniswap/v2-core
cd v2-core
forge install
forge test --rpc-url https://testnet-rpc.citrate.ai
forge create --rpc-url https://testnet-rpc.citrate.ai \
             --private-key $PRIVATE_KEY \
             src/UniswapV2Factory.sol:UniswapV2Factory
```

Works identically to Ethereum.

### How do I deploy an AI model?

**Step 1: Upload weights to IPFS**
```bash
# Using IPFS CLI
ipfs add llama-3-70b-weights.safetensors
# Output: QmXnnyufdzAWL5CqZ2RnSNgPbvCc1ALT73s6epPrRnZ1Xy
```

**Step 2: Register model via contract**
```typescript
import { ModelRegistry } from "@citrate-ai/sdk";

const registry = new ModelRegistry(client);

const model = await registry.deployModel({
  weights: "QmXnnyufdzAWL5CqZ2RnSNgPbvCc1ALT73s6epPrRnZ1Xy",
  architecture: "transformer",
  metadata: {
    name: "Llama 3 70B Instruct",
    description: "Instruction-tuned LLM",
    parameters: "70B",
    contextLength: 8192
  },
  accessPolicy: {
    type: "pay-per-inference",
    pricePerToken: 0.0001 // 0.0001 LATT per token
  }
});

console.log(`Model deployed with ID: ${model.id}`);
```

**Step 3: Users can now call your model**
```typescript
const response = await client.inference.run({
  model: model.id,
  input: "Explain quantum entanglement",
  maxTokens: 500,
  payment: 0.1 // LATT
});

// You earn 70% of the fee automatically
```

**Full Guide**: https://docs.citrate.ai/deploy-model

### What's the gas cost for AI operations?

**Model Registration**:
```
Base: 100,000 gas
Per byte of metadata: 1,000 gas

Example (500 bytes metadata):
100,000 + (500 * 1,000) = 600,000 gas
At 10 Gwei: 0.006 LATT (~$0.006)
```

**Inference Execution** (dynamic):
```
Base: 50,000 gas
Per input token: 100 gas
Per output token: 200 gas
Model loading: 1,000 gas per MB (cached after first load)

Example (Llama 3 70B: 100 input, 500 output):
50,000 + (100 * 100) + (500 * 200) + 0 (cached)
= 50,000 + 10,000 + 100,000
= 160,000 gas
At 10 Gwei: 0.0016 LATT (~$0.0016)
```

**Tensor Operations**:
```
Matrix multiply (1024×1024): ~10,000 gas
Softmax (1024 elements): ~1,000 gas
Batch norm (1024 elements): ~1,500 gas
```

**ZK Proofs**:
```
Proof generation: 1,000,000+ gas (expensive, do off-chain)
Proof verification: 50,000-200,000 gas (optimized for on-chain)
```

**Comparison to Ethereum**:
- Standard operations (SSTORE, CALL, etc.) have **identical cost** to Ethereum
- AI operations are priced based on computational cost (FLOPs, memory)

### Can I use MetaMask?

**Yes!** Citrate is EVM-compatible, so MetaMask works out of the box.

**Add Citrate Testnet to MetaMask**:
```
Network Name: Citrate Testnet
RPC URL: https://testnet-rpc.citrate.ai
Chain ID: 1337
Currency Symbol: LATT
Block Explorer: https://testnet-explorer.citrate.ai
```

**Add Citrate Mainnet**:
```
Network Name: Citrate
RPC URL: https://rpc.citrate.ai
Chain ID: 1
Currency Symbol: LATT
Block Explorer: https://explorer.citrate.ai
```

**Get Testnet Tokens**: Visit https://faucet.citrate.ai and enter your address.

### What development tools are supported?

**Smart Contract Frameworks**:
- ✅ Hardhat (full support)
- ✅ Foundry (recommended)
- ✅ Remix (works in browser)
- ✅ Truffle (legacy support)

**Libraries**:
- ✅ Ethers.js v5 and v6
- ✅ Web3.js
- ✅ Viem
- ✅ @citrate-ai/sdk (official TypeScript SDK)
- ✅ citrate-sdk (official Python SDK)

**Wallets**:
- ✅ MetaMask
- ✅ Ledger
- ✅ Trezor
- ✅ WalletConnect
- ✅ Citrate CLI Wallet (native Ed25519)

**Block Explorers**:
- Citrate Explorer (https://explorer.citrate.ai)
- DAG Visualizer (https://dag.citrate.ai)

**IDEs**:
- ✅ VS Code (Solidity extension works)
- ✅ Citrate Studio (visual IDE with Monaco editor)
- ✅ Remix (web IDE)

### How do I test my contracts locally?

**Option 1: Run a local devnet node**
```bash
# Install Citrate
npm install -g @citrate-ai/cli

# Start local devnet
citrate devnet start

# Node runs at http://localhost:8545 (EVM-compatible RPC)
# Chain ID: 1337
# Pre-funded accounts with 100 LATT each
```

**Option 2: Use Foundry's built-in testing**
```bash
# Citrate contracts work with forge test
forge test

# Run against local devnet
forge test --rpc-url http://localhost:8545
```

**Option 3: Connect to public testnet**
```bash
forge test --rpc-url https://testnet-rpc.citrate.ai
```

---

## For Validators

### How do I become a validator?

**Minimum Requirements**:
- **Stake**: 10,000 LATT (can self-bond or receive delegations)
- **Hardware**: 16 CPU cores, 64 GB RAM, 1 TB NVMe SSD, 1 Gbps network
- **Optional GPU**: NVIDIA A100 or better (for AI inference rewards)

**Setup Steps**:

**1. Install the validator software**:
```bash
curl -sSL https://get.citrate.ai | bash
citrate --version
```

**2. Initialize validator keys**:
```bash
citrate validator init --keyfile validator.key
# Generates Ed25519 keypair for block signing
```

**3. Stake tokens**:
```bash
citrate validator stake --amount 10000 --keyfile validator.key
```

**4. Start the validator**:
```bash
citrate validator start \
  --keyfile validator.key \
  --rpc-port 8545 \
  --p2p-port 9000 \
  --enable-inference  # Optional: earn AI inference bonuses
```

**5. Monitor status**:
```bash
citrate validator status
# Shows: uptime, blocks produced, rewards earned, delegation
```

**Full Guide**: https://docs.citrate.ai/validators

### What are the rewards?

**Block Rewards**:
```
Base: 10 LATT per block
Inference bonus: +1% per AI inference in block
Storage bonus: +0.5% per GB of artifacts pinned
Congestion bonus: Up to +50% during high network load
```

**Finality Committee**:
- Committee members earn 30% of all transaction fees
- Committee rotates every 1,000 blocks (~30 minutes)
- Top 100 validators by stake are in the committee

**Example Monthly Earnings**:
```
Assumptions:
- Validator stake: 100,000 LATT (0.01% of total staked)
- Average block reward: 12 LATT (including bonuses)
- Blocks per month: 1,296,000 (at 2-second block time)
- Total monthly rewards: 15,552,000 LATT
- Validator's share: 15,552,000 * 0.0001 = 1,555 LATT/month

At $1/LATT: $1,555/month
At $10/LATT: $15,550/month
```

**APY Calculation**:
```
Annual rewards = 1,555 * 12 = 18,660 LATT
APY = 18,660 / 100,000 = 18.66%

Note: APY decreases as more tokens are staked
```

### What happens if I go offline?

**Short Downtime** (<10% missed blocks in 24 hours):
- No penalty
- Lost rewards for missed blocks

**Extended Downtime** (>10% missed blocks in 24 hours):
- Slashing: 0.1% of stake per day
- Jailed (prevented from producing blocks)
- Can unjail after 7 days by paying 1,000 LATT

**Severe Downtime** (>50% missed blocks in 7 days):
- Slashing: 1% of stake
- Delegators may undelegate
- Reputation damage

**Best Practice**: Use monitoring tools and automated failover.
```bash
# Setup monitoring
citrate validator monitor --alert-email your@email.com

# Automated failover
citrate validator failover --backup-node backup.yourdomain.com
```

### Can I run a validator on cloud providers?

**Yes!** Most validators run on AWS, GCP, or dedicated providers.

**Recommended Setups**:

**AWS**:
- Instance: `c5.4xlarge` (16 vCPU, 32 GB RAM)
- Storage: 1 TB `gp3` EBS
- GPU (optional): `p3.2xlarge` (NVIDIA V100)
- Cost: ~$300/month (CPU-only), ~$3,500/month (with GPU)

**GCP**:
- Instance: `n2-standard-16` (16 vCPU, 64 GB RAM)
- Storage: 1 TB SSD persistent disk
- GPU (optional): `a2-highgpu-1g` (NVIDIA A100)
- Cost: ~$350/month (CPU-only), ~$4,000/month (with GPU)

**Dedicated Providers** (recommended):
- **Latitude.sh**: ~$200/month bare metal
- **Hetzner**: ~$150/month dedicated servers
- **OVH**: ~$180/month dedicated servers

**Important**: Ensure low latency (<100 ms to other validators). Use regions with good connectivity to North America, Europe, and Asia.

### Do I need a GPU?

**Required**: No
**Recommended**: Yes (for AI inference bonuses)

**Without GPU**:
- Can still produce blocks and earn base rewards
- Miss out on inference bonuses (~20-30% extra rewards)

**With GPU**:
- Earn +1% per inference execution in your blocks
- Average 20-50 inferences per block during active usage
- Bonus: +20-50% on block rewards

**Minimum GPU**:
- NVIDIA RTX 3090 (24 GB VRAM)
- Can run models up to 20B parameters

**Recommended GPU**:
- NVIDIA A100 (40 GB or 80 GB VRAM)
- Can run models up to 70B parameters
- Future-proof for larger models

**Cost-Benefit**:
```
GPU Cost: ~$3,000/month (A100 on cloud)
Extra rewards: +30% on block rewards
Base monthly earnings: $1,555
With GPU: $1,555 * 1.30 = $2,022
Extra income: $467/month

ROI: Negative on cloud, positive if you own hardware
```

**Recommendation**: Start CPU-only, add GPU if AI inference becomes popular.

---

## For AI Researchers

### How do I monetize my AI models?

**Deploy your model to Citrate** and earn fees every time someone uses it.

**Revenue Model**:
```
User pays inference fee → Split:
- 70% to you (model owner)
- 20% to validator (who ran the inference)
- 10% to protocol treasury
```

**Pricing Models**:

**1. Pay-Per-Inference**:
```solidity
accessPolicy: {
  type: "pay-per-inference",
  pricePerToken: 0.0001 LATT  // You set the price
}
```

**2. Subscription**:
```solidity
accessPolicy: {
  type: "subscription",
  monthlyFee: 100 LATT
}
```

**3. Free (Open Source)**:
```solidity
accessPolicy: {
  type: "public",
  price: 0
}
// You can still earn tips from grateful users
```

**Example Earnings**:
```
Model: Llama 3 70B fine-tuned for legal analysis
Price: 0.0005 LATT per token
Usage: 10 million tokens per month

Monthly revenue:
10,000,000 tokens * 0.0005 LATT/token * 0.70 (your share)
= 3,500 LATT/month
= $3,500/month at $1/LATT
= $35,000/month at $10/LATT
```

### Can I keep my model weights private?

**Yes!** Citrate supports **private models** with cryptographic access control.

**Option 1: Encrypted Weights**:
```typescript
// Encrypt weights before uploading to IPFS
const encryptedWeights = encrypt(weights, yourSecretKey);
const ipfsCID = await uploadToIPFS(encryptedWeights);

// Register model
await registry.deployModel({
  weights: ipfsCID,
  encryption: {
    algorithm: "AES-256-GCM",
    accessControl: "subscription"  // Only paying subscribers get decryption key
  }
});
```

**Option 2: Trusted Execution Environment (TEE)**:
```
Validators run inference inside Intel SGX or AMD SEV enclaves
Weights are decrypted only inside enclave (hardware-protected)
Even validator operator cannot see weights
```

**Option 3: Multi-Party Computation (MPC)** (future):
```
Model weights split across multiple validators
Inference runs collaboratively without any single party seeing full weights
Slower but maximum privacy
```

### How do I update my model?

**Versioning is built-in**:
```typescript
// Deploy version 1.0
const v1 = await registry.deployModel({
  weights: "QmVersion1...",
  version: "1.0.0"
});

// Later: deploy version 1.1 with improved weights
const v1_1 = await registry.updateModel({
  modelId: v1.id,
  weights: "QmVersion1_1...",
  version: "1.1.0",
  changelog: "Improved accuracy on medical queries"
});

// Users can specify version:
await client.inference.run({
  model: v1.id,
  version: "1.1.0",  // Or "latest"
  input: "..."
});
```

**Backward Compatibility**:
- Old versions remain accessible (immutable on IPFS)
- Users can pin to specific version if needed
- Default: use latest version

### Can I collaborate with other researchers?

**Yes!** Use **federated learning** to train models collaboratively.

**Workflow**:
```typescript
// Create federated learning job
const job = await federatedLearning.createJob({
  baseModel: "llama-3-70b",
  task: "medical-diagnosis",
  dataset: "ipfs://QmMedicalDataSpec...",  // Dataset specification (not actual data)
  minContributors: 100,
  reward: 10000  // 10,000 LATT split among contributors
});

// Contributors train locally on their private data
await job.submitGradient({
  gradient: localGradient,  // Computed on your private data
  proof: zkProof  // Proves you trained correctly without revealing data
});

// After 100 contributions, aggregated model is published
const improvedModel = await job.finalizeModel();
// All contributors earn rewards proportional to their contribution quality
```

**Use Cases**:
- **Medical AI**: Hospitals train on patient data without sharing records
- **Financial Models**: Banks train fraud detection without sharing transactions
- **Personal Assistants**: Users improve models while keeping conversations private

### What about LoRA adapters?

**LoRA (Low-Rank Adaptation)** is fully supported and **highly recommended** for efficient fine-tuning.

**Why LoRA?**
- Fine-tune 70B model with only **100 MB adapter** (vs. 140 GB full weights)
- Cheap to store and distribute on-chain
- Can mix and match: `base_model + adapter_A + adapter_B`

**Deploy a LoRA adapter**:
```typescript
const lora = await loraFactory.createLoRA({
  baseModel: "llama-3-70b",
  dataset: "ipfs://QmMyDataset...",
  rank: 16,
  alpha: 32,
  targetModules: ["q_proj", "v_proj"]  // Which layers to adapt
});

// Inference automatically combines base + adapter
const result = await client.inference.run({
  model: lora.id,
  input: "Your specialized query"
});
```

**Marketplace**:
- Base models are expensive to train but reusable
- LoRA adapters are cheap to create and highly specialized
- Users pay for base model + adapter combination
- You earn fees on your adapter

**Example**:
```
Base model: Llama 3 70B (general purpose)
Your adapter: Legal contract analysis
User query: "Summarize this employment contract"

Inference uses: Llama 3 70B + your legal adapter
Revenue split:
- 50% to base model owner
- 50% to adapter owner (you)
```

---

## Economics & Tokenomics

### What is the LATT token?

**LATT** (Citrate native token) has three functions:

1. **Gas fees**: Pay for transactions and AI inference
2. **Staking**: Validators stake LATT to earn block rewards
3. **Governance**: Vote on protocol upgrades and parameter changes

**Total Supply**: 1,000,000,000 LATT (fixed, no inflation beyond tail emission)

**Distribution**:
- 50% Mining rewards (10-year emission)
- 25% Ecosystem fund (grants, partnerships)
- 15% Team & advisors (4-year vest with 1-year cliff)
- 10% Treasury (protocol operations)

### How do I acquire LATT tokens?

**Before Mainnet Launch**:
- Private sale (for accredited investors)
- Public sale (token generation event)
- Testnet faucet (free testnet tokens for development)

**After Mainnet Launch**:
- Exchanges (CEX and DEX)
- Earn by running a validator
- Earn by deploying popular AI models
- Earn by contributing to federated learning jobs

**No ICO**: Citrate uses a fair launch model with gradual emission.

### What's the emission schedule?

**Block Rewards**:
```
Blocks 0 - 2,100,000:       10 LATT per block (first ~4 years)
Blocks 2,100,001 - 4,200,000: 5 LATT per block (years 5-8)
Blocks 4,200,001 - 6,300,000: 2.5 LATT per block (years 9-12)
Blocks 6,300,001+:            0.1 LATT per block (perpetual tail emission)
```

**Total Emission**:
```
First 4 years:  21,000,000 blocks * 10 LATT = 210,000,000 LATT
Next 4 years:   21,000,000 blocks * 5 LATT = 105,000,000 LATT
Next 4 years:   21,000,000 blocks * 2.5 LATT = 52,500,000 LATT
Next 4 years:   21,000,000 blocks * 1.25 LATT = 26,250,000 LATT
...
Total after 10 years: ~500,000,000 LATT (matches allocation)
```

**Tail Emission**: 0.1 LATT per block forever (to ensure validator incentives don't go to zero).

### What's the expected LATT price?

**We don't speculate on price**, but here's a valuation framework:

**Comparable Projects**:
| Project | Market Cap | Token Price | Use Case |
|---------|-----------|-------------|----------|
| Ethereum | $200B | $1,600 | Smart contracts |
| Solana | $20B | $50 | High-performance smart contracts |
| ICP | $3B | $6 | Decentralized compute |
| Kaspa | $2B | $0.10 | High-throughput currency |

**Citrate Value Drivers**:
1. AI inference volume (more usage = more fees = more LATT burned = deflationary)
2. Model marketplace GMV (gross merchandise value)
3. Total value locked in DeFi (Citrate-based lending, DEXs, etc.)
4. Validator staking (more staked = less circulating supply)

**Hypothetical Scenario** (not financial advice):
```
If Citrate captures:
- 1% of AI inference market ($200M/year)
- 0.1% of DeFi TVL ($1B locked)
- 10,000 validators staking 30M LATT total

Then:
Circulating supply: 250M LATT (after 4 years, excluding staked)
Revenue: $200M/year
Revenue multiple: 10x (typical for growth tech)
Market cap: $2B
Token price: $2B / 250M = $8/LATT

Note: This is purely illustrative, not a price prediction.
```

### Is LATT deflationary?

**Yes, partially.**

**Burn Mechanisms**:
1. **Transaction fees**: 20% of all fees are burned
2. **Slashing**: Penalized validator stakes are burned
3. **Model registry fees**: 10% of registration fees are burned

**Emission**:
- Block rewards add new supply
- Emission decreases over time (halvings)
- Perpetual tail emission (0.1 LATT/block) to sustain validators

**Net Effect**:
- **Early years**: Inflationary (emission > burn)
- **Later years**: Potentially deflationary (burn > tail emission)
- Depends on network usage (high usage = more burns)

**Example**:
```
Year 10+ (tail emission):
New supply: 0.1 LATT * 15,768,000 blocks/year = 1,576,800 LATT/year

If network processes 1M transactions/day:
Fees: 1M tx * 0.001 LATT/tx * 365 days = 365,000 LATT/year
Burned: 365,000 * 0.20 = 73,000 LATT/year

Net: +1,503,800 LATT/year (~0.15% inflation)

If network processes 10M transactions/day:
Burned: 3,650,000 * 0.20 = 730,000 LATT/year
Net: +846,800 LATT/year (~0.08% inflation)

If network processes 50M transactions/day:
Burned: 18,250,000 * 0.20 = 3,650,000 LATT/year
Net: -2,073,200 LATT/year (~0.2% deflation)
```

**High usage → deflationary pressure → token appreciation (in theory).**

---

## Security & Privacy

### Is Citrate secure?

Citrate employs **defense-in-depth** security:

**Consensus Security**:
- GhostDAG proven secure if <50% Byzantine
- BFT checkpoints require 2/3+ honest committee
- VRF-based leader election (prevents manipulation)

**Execution Security**:
- EVM compatibility = battle-tested security model
- All standard Ethereum defenses (reentrancy guards, SafeMath, etc.)
- AI precompiles sandboxed (cannot access validator file system)

**Cryptographic Security**:
- Ed25519 signatures (RFC 8032 standard)
- ECDSA (secp256k1, same as Bitcoin/Ethereum)
- SHA3-256 (Keccak) for hashing
- ZK proofs (PLONK, Groth16, STARKs)

**Network Security**:
- Sybil resistance via staking
- DDoS mitigation (rate limiting, peer limits)
- Eclipse attack prevention (diverse peer discovery)

**Audits**:
- ✅ Consensus layer audited by [Security Firm]
- ✅ Execution layer audited by [Security Firm]
- ✅ Smart contracts audited by OpenZeppelin
- ⏳ Formal verification in progress

### Has Citrate been audited?

**Yes**:
- Consensus layer: Audited by [Security Firm] (report: https://audits.citrate.ai/consensus-2024.pdf)
- Execution layer: Audited by [Security Firm] (report: https://audits.citrate.ai/execution-2024.pdf)
- Smart contracts: Audited by OpenZeppelin (report: https://audits.citrate.ai/contracts-2024.pdf)

**Formal Verification**:
- Governance contracts: ✅ Verified with Certora
- ModelRegistry: ⏳ In progress
- LoRAFactory: ⏳ Planned

**Bug Bounty**:
- Critical: Up to $100,000
- High: Up to $50,000
- Medium: Up to $10,000
- Program: https://bugbounty.citrate.ai

### Can validators steal my AI models?

**No**, for multiple reasons:

**1. Models are content-addressed (IPFS)**:
- Anyone can access the model weights (they're on IPFS)
- The **value** is in the on-chain metadata and reputation

**2. Access control is enforced**:
```solidity
// If model is private or pay-per-use:
function runInference(ModelId id, bytes input) external payable {
    require(checkAccess(id, msg.sender), "Access denied");
    // Payment required before validator can run inference
}
```

**3. Encrypted models** (optional):
- Encrypt weights before uploading
- Only paying users get decryption key
- Validator runs inference in TEE (encrypted memory)

**4. Reputation system**:
- Validators who cheat (wrong outputs, censorship) get slashed
- Users can verify inference outputs via ZK proofs

**Worst Case**: Validator could copy your public model and redeploy it. But:
- Your original model has on-chain provenance and reputation
- Users will prefer established, verified models
- Community can flag copycats

**Best Practice**: Use encrypted weights or LoRA adapters (harder to steal).

### Is my data private when using AI inference?

**It depends on your threat model**:

**Default (No Privacy)**:
- Inputs and outputs are **not private** from the validator running inference
- Validator sees your prompts and model responses
- Similar to using OpenAI API (they see your prompts too)

**Privacy Options**:

**1. Trusted Validators**:
- Choose validators with good reputation
- Validators stake tokens (risk slashing if they leak data)

**2. Trusted Execution Environments (TEE)**:
- Inference runs inside Intel SGX or AMD SEV enclave
- Even validator operator cannot see inputs/outputs
- Cryptographic attestation proves TEE was used

**3. Zero-Knowledge Inference** (future):
- Fully homomorphic encryption (FHE) allows computation on encrypted data
- Validator never sees plaintext
- Very slow (100-1000x overhead)

**4. Multi-Party Computation (MPC)** (future):
- Split inference across multiple validators
- No single validator sees full input or output
- Requires coordination (slower)

**Recommendation**:
- Non-sensitive queries: Use default (fast, cheap)
- Sensitive queries: Use TEE (moderate overhead)
- Highly sensitive: Wait for ZK/MPC (future)

### What if Citrate gets attacked?

**Citrate has multiple layers of defense**:

**51% Attack** (attacker controls >50% of stake):
- **Cost**: Must acquire 500M+ LATT (~$500M+ at $1/LATT)
- **Detection**: Community notices unusual voting patterns
- **Response**: Social consensus forks to exclude attacker
- **Outcome**: Attacker loses stake in the fork (economic loss)

**Censorship Attack**:
- **GhostDAG includes all blocks** (even from censored validators)
- Maximum censorship delay: ~12 seconds (time to finality)
- Repeated censorship can be penalized via governance

**Sybil Attack** (create many fake validators):
- **Defense**: Staking requirement (10,000 LATT minimum)
- Creating 1000 fake validators costs 10M LATT
- Doesn't increase attack power (voting is stake-weighted, not count-weighted)

**Smart Contract Bugs**:
- **Defense**: Audits, formal verification, bug bounties
- **Response**: Governance can upgrade contracts (with time-lock delay)
- **Last Resort**: Social consensus hard fork (if catastrophic)

**Long-Range Attack** (rewrite history):
- **Defense**: Checkpoints every 100,000 blocks
- Clients reject chains diverging before latest checkpoint
- Cannot rewrite checkpointed history even with 100% of old stake

**DDoS**:
- **Defense**: Rate limiting, peer limits, mempool size caps
- Validators distributed globally (hard to target all)
- Network degradation (slower blocks) but not full outage

---

## Roadmap & Future

### When is mainnet launch?

**Current Phase**: Testnet (public since Q4 2024)

**Roadmap**:
- ✅ **Phase 1**: Consensus + execution (completed)
- ✅ **Phase 2**: Core infrastructure (completed)
- ✅ **Phase 3**: Developer tools (completed)
- 🚧 **Phase 4**: Model marketplace (in progress, Week 3)
- 📅 **Phase 5**: Advanced features (Q1 2025)
- 📅 **Phase 6**: Mainnet launch (Q2 2025)

**Mainnet Prerequisites**:
1. ✅ Testnet running stably for 6+ months
2. ⏳ 3 independent security audits completed
3. ⏳ Bug bounty program (3 months, no critical bugs)
4. ⏳ Validator onboarding (100+ independent validators)
5. ⏳ Governance framework tested
6. ⏳ Emergency pause mechanism tested

**Timeline**: Targeting **April-June 2025** for mainnet genesis.

### What's coming in Phase 5?

**Advanced Features (Q1 2025)**:

1. **Federated Learning Framework**:
   - Train models collaboratively without sharing data
   - ZK proofs of correct training
   - Automated reward distribution

2. **Cross-Chain Bridges**:
   - Ethereum bridge (lock LATT, mint wLATT on Ethereum)
   - Cosmos IBC integration
   - Bitcoin atomic swaps (HTLCs)

3. **Privacy Features**:
   - Confidential transactions (hide amounts)
   - ZK inference (encrypted inputs/outputs)
   - Private model weights (TEE support)

4. **LoRA at Scale**:
   - Automated LoRA training jobs
   - Adapter marketplace
   - Dynamic adapter composition

5. **Optimistic Rollups** (Layer 2):
   - High-frequency inference (10x throughput)
   - Lower fees for experimentation
   - Fraud proofs for security

### Will Citrate support [insert feature]?

**Likely "Yes" if it fits our vision**:
- AI/ML-related features
- Scaling improvements (sharding, Layer 2s)
- Privacy enhancements (ZK, MPC)
- Developer tools and SDKs
- Cross-chain interoperability

**Likely "No" if it diverges from core mission**:
- Features unrelated to AI or smart contracts
- Changes that compromise decentralization
- Breaking EVM compatibility

**Governance decides**: Token holders vote on major protocol changes.

**Request a Feature**: https://github.com/citrate-ai/citrate/discussions

### Can I contribute to Citrate?

**Yes! Citrate is open-source** (Apache 2.0 license).

**Ways to Contribute**:

1. **Code**:
   - GitHub: https://github.com/citrate-ai/citrate
   - Issues: https://github.com/citrate-ai/citrate/issues
   - PRs welcome (check CONTRIBUTING.md)

2. **Documentation**:
   - Improve docs, write tutorials
   - Translate to other languages

3. **Testing**:
   - Run testnet nodes, report bugs
   - Security testing (bug bounty)

4. **Ecosystem**:
   - Build dapps on Citrate
   - Deploy AI models
   - Create developer tools

5. **Community**:
   - Answer questions on Discord
   - Write blog posts, create videos
   - Organize meetups and hackathons

**Grants Available**: Apply at https://grants.citrate.ai

### Is there a DAO?

**Yes, Citrate governance is decentralized**:

**Governance Token**: LATT (1 LATT = 1 vote)

**What Can Be Governed**:
- Protocol parameters (k, max_parents, gas prices)
- Treasury spending (ecosystem fund allocation)
- Protocol upgrades (consensus changes, new precompiles)
- Emergency actions (pause network, fix critical bugs)

**Proposal Process**:
1. Submit proposal (requires 100,000 LATT deposit)
2. Discussion period (7 days)
3. Voting period (14 days)
4. Execution (if >50% yes votes and 10% quorum)

**Delegation**:
- Delegate voting power to representatives
- Non-custodial (you keep your tokens)
- Can change delegation anytime

**Current Governance**: Foundation-led (until mainnet launch), then progressively decentralized.

---

## Getting Help

### Where can I get support?

**Documentation**: https://docs.citrate.ai
**Discord**: https://discord.gg/citrate (most active)
**Telegram**: https://t.me/citrate
**Twitter**: @CitrateAI
**GitHub Discussions**: https://github.com/citrate-ai/citrate/discussions
**Email**: hello@citrate.ai (non-urgent)

**For Developers**:
- Developer Discord channel: #dev-support
- Stack Overflow: Tag questions with `citrate`

**For Validators**:
- Validator Telegram: https://t.me/citrate-validators
- Validator docs: https://docs.citrate.ai/validators

**For Security Issues**:
- **DO NOT** disclose publicly
- Email: security@citrate.ai (PGP key: https://citrate.ai/pgp)

### How do I report a bug?

**Non-Security Bugs**:
- GitHub Issues: https://github.com/citrate-ai/citrate/issues
- Include: Citrate version, OS, reproduction steps, error logs

**Security Bugs**:
- Email: security@citrate.ai
- Include: Detailed description, reproduction steps, PoC code
- Eligible for bug bounty (up to $100,000)

**Response Time**:
- Critical bugs: <4 hours
- High severity: <24 hours
- Medium severity: <3 days
- Low severity: <7 days

### Where can I learn more?

**Essential Reading**:
- White Paper: https://citrate.ai/whitepaper.pdf
- Documentation: https://docs.citrate.ai
- GitHub: https://github.com/citrate-ai/citrate

**Tutorials**:
- Getting Started: https://docs.citrate.ai/getting-started
- Deploy Your First Model: https://docs.citrate.ai/deploy-model
- Build a dapp: https://docs.citrate.ai/tutorials/dapp

**Videos**:
- YouTube: https://youtube.com/@citrate-ai
- Intro to Citrate (10 min): [Link]
- Technical Deep Dive (45 min): [Link]

**Research Papers**:
- GhostDAG: Sompolinsky & Zohar (2018)
- Model Context Protocol: Anthropic (2024)
- Citrate Architecture: [Link to paper]

**Community**:
- Discord: https://discord.gg/citrate
- Twitter: @CitrateAI
- Reddit: r/citrate

---

## Still Have Questions?

**Join our Discord**: https://discord.gg/citrate

Our community and core team are happy to help!

---

*Last Updated: October 27, 2025*
*For the latest version, visit: https://docs.citrate.ai/faq*
